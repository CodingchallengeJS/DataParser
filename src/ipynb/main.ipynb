{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d1f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "options.add_experimental_option(\"prefs\", {\n",
    "  \"download.default_directory\": \"D\\\\Python\\\\DataForge-automated\\\\MathTHPT2025\",\n",
    "  \"download.prompt_for_download\": False,\n",
    "  \"download.directory_upgrade\": True,\n",
    "  \"safebrowsing.enabled\": False,\n",
    "  \"safebrowsing.ebabled\": \"false\"\n",
    "})\n",
    "driver = webdriver.Chrome(options=options)\n",
    "useOutsideOCR = 1\n",
    "driver.get(\"https://dotsocr.xiaohongshu.com/\" if useOutsideOCR == 1 else \"https://dotsocr.trunghsgs.edu.vn/\")\n",
    "\n",
    "try:\n",
    "    wait = WebDriverWait(driver, 60)\n",
    "except NameError:\n",
    "    wait = WebDriverWait(driver, 60)\n",
    "\n",
    "try:\n",
    "    wait.until(lambda d: d.execute_script(\"return document.readyState\") == \"complete\")\n",
    "\n",
    "    try:\n",
    "        wait.until(EC.presence_of_element_located((By.ID, \"parse_button\")))\n",
    "    except Exception:\n",
    "        try:\n",
    "            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"input[type='file']\")))\n",
    "        except Exception:\n",
    "            pass\n",
    "    time.sleep(1) \n",
    "    print(\"Page loaded\")\n",
    "except Exception as e:\n",
    "    print(\"Timeout waiting for page to load:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4e2400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os, json, re\n",
    "\n",
    "env_path = find_dotenv()\n",
    "if env_path:\n",
    "    load_dotenv(env_path)\n",
    "    print(f\"Loaded .env from: {env_path}\")\n",
    "else:\n",
    "    load_dotenv()\n",
    "    print(\"No .env file found; loaded environment from system variables\")\n",
    "    \n",
    "data_dir = os.environ.get(\"DATA_DIR\", \"MathTHPT2025\")\n",
    "loading_folder_env = os.environ.get(\"LOADING_FOLDER\", '[\"1.Chuyen de\", \"2.De chac diem 8\", \"3.De chac diem 9\", \"4.De luyen them\", \"5.De quan trong\", \"6.De so\"]')\n",
    "try:\n",
    "    loading_folder = json.loads(loading_folder_env)\n",
    "except Exception:\n",
    "    try:\n",
    "        loading_folder = ast.literal_eval(loading_folder_env)\n",
    "    except Exception:\n",
    "        loading_folder = [s.strip() for s in re.split(r'[;,]', loading_folder_env) if s.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f7193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "log_dir = Path(data_dir)\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "log_path = log_dir / \"process.log\"\n",
    "\n",
    "logger = logging.getLogger(\"pdf_processor\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# avoid adding duplicate handlers when re-running the cell\n",
    "if not any(isinstance(h, RotatingFileHandler) and h.baseFilename == str(log_path) for h in logger.handlers):\n",
    "    fh = RotatingFileHandler(str(log_path), maxBytes=5 * 1024 * 1024, backupCount=5, encoding=\"utf-8\")\n",
    "    fh.setLevel(logging.INFO)\n",
    "    fmt = logging.Formatter(\"%(asctime)s %(levelname)s: %(message)s\", \"%Y-%m-%d %H:%M:%S\")\n",
    "    fh.setFormatter(fmt)\n",
    "    logger.addHandler(fh)\n",
    "\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.INFO)\n",
    "    ch.setFormatter(fmt)\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "# convenience alias (use logger.info(...) or log(...))\n",
    "log = logger.info\n",
    "for folder in loading_folder:\n",
    "    pdf_files = []\n",
    "    folder_path = os.path.join(data_dir, folder)\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.lower().endswith('.pdf'): #Duyet tung file pdf\n",
    "            pdf_files.append(file)\n",
    "            file_path = os.path.abspath(os.path.join(folder_path, file))\n",
    "\n",
    "            #upload file\n",
    "            file_input = driver.find_element(By.CSS_SELECTOR, \"input[type='file'][data-testid='file-upload']\")\n",
    "            file_input.send_keys(file_path)\n",
    "\n",
    "            print(\"Sent file to upload input:\", file_path)\n",
    "\n",
    "            #doi upload xong thi click nut parse\n",
    "            upload_selector = \"span.uploading\"\n",
    "            timeout1 = 1800\n",
    "            try:\n",
    "                upload_wait = WebDriverWait(driver, timeout1)\n",
    "                upload_wait.until(EC.invisibility_of_element_located((By.CSS_SELECTOR, upload_selector)))\n",
    "                print(\"Upload indicator disappeared\")\n",
    "            except Exception as e:\n",
    "                print(\"Timeout waiting for upload indicator to disappear:\", e)\n",
    "            time.sleep(2)\n",
    "            parse_btn = driver.find_element(By.ID, \"parse_button\")\n",
    "            parse_btn.click()\n",
    "            print(\"Clicked parse button\")\n",
    "            try:\n",
    "                tab_btn = WebDriverWait(driver, 30).until(EC.element_to_be_clickable((By.ID, \"component-38-button\")))\n",
    "                tab_btn.click()\n",
    "                print(\"Clicked Markdown Raw Text tab\")\n",
    "            except Exception as e:\n",
    "                print(\"Failed to click Markdown Raw Text tab:\", e)\n",
    "\n",
    "            file_no_ext = os.path.splitext(file)[0]\n",
    "            download_dir = os.path.join(\"..\\\\..\\\\output\", folder, file_no_ext, \"\")\n",
    "\n",
    "            target_download_dir = os.path.join(os.getcwd(), download_dir)\n",
    "            os.makedirs(target_download_dir, exist_ok=True)\n",
    "            download_dir = target_download_dir\n",
    "            before_files = set(os.listdir(download_dir))\n",
    "\n",
    "            try:\n",
    "                driver.execute_cdp_cmd(\"Page.setDownloadBehavior\", {\"behavior\": \"allow\", \"downloadPath\": os.path.join(os.getcwd(), download_dir)})\n",
    "            except Exception as e:\n",
    "                print(\"Could not set download directory via CDP:\", e)\n",
    "\n",
    "            wait = WebDriverWait(driver, 1800)\n",
    "            btn = wait.until(EC.element_to_be_clickable((By.ID, \"component-45\")))\n",
    "            print(\"Target download dir:\", os.path.join(os.getcwd(), download_dir))\n",
    "            print(\"Download button found, clicking...\")\n",
    "            btn.click()\n",
    "\n",
    "            #doi download xong\n",
    "            timeout = 1800\n",
    "            end_time = time.time() + timeout\n",
    "            downloaded = None\n",
    "            while time.time() < end_time:\n",
    "                time.sleep(0.5)\n",
    "                new_files = set(os.listdir(download_dir)) - before_files\n",
    "                if new_files:\n",
    "                    for f in new_files:\n",
    "                        if not f.endswith('.crdownload'):\n",
    "                            downloaded = f\n",
    "                            break\n",
    "                if downloaded:\n",
    "                    break\n",
    "\n",
    "            if downloaded:\n",
    "                print(\"Downloaded file:\", downloaded)\n",
    "            else:\n",
    "                print(\"No completed download detected within timeout.\")\n",
    "            \n",
    "            #giai nen file\n",
    "            import os, zipfile\n",
    "            import logging\n",
    "            from logging.handlers import RotatingFileHandler\n",
    "            from pathlib import Path\n",
    "\n",
    "            zip_path = os.path.join(download_dir, downloaded)  # uses existing vars\n",
    "            extract_to = os.path.join(\"..\\\\..\\\\output\", folder, file_no_ext, \"output\", \"all_pages\")\n",
    "            os.makedirs(os.path.join(\"..\\\\..\\\\output\", folder, file_no_ext, \"output\", \"all_pages\"), exist_ok=True)\n",
    "            with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "                z.extractall(extract_to)\n",
    "\n",
    "            print(\"Extracted:\", zip_path, \"->\", extract_to)\n",
    "\n",
    "            #ghep lai thanh 1 file md\n",
    "            suffix = os.path.splitext(f)[0].split('_')[-1]  # e.g. 'ef13eefa' from 'layout_results_ef13eefa.zip'\n",
    "            final_path = os.path.join(\"..\\\\..\\\\output\", folder, file_no_ext, \"output\", \"final.md\")\n",
    "            #os.makedirs(os.path.join(\"..\\\\..\\\\output\", folder, file_no_ext, \"output\"), exist_ok=True)\n",
    "            with open(final_path, \"w\", encoding=\"utf-8\") as out_f:\n",
    "                for i in range(0, 100):\n",
    "                    part_name = f\"demo_{suffix}_page_{i}.md\"\n",
    "                    part_path = os.path.join(extract_to, part_name)\n",
    "                    if not os.path.exists(part_path):\n",
    "                        #print(\"Missing:\", part_name)\n",
    "                        continue\n",
    "                    with open(part_path, \"r\", encoding=\"utf-8\") as part_f:\n",
    "                        content = part_f.read()\n",
    "                    # separate pages with two newlines to keep markdown blocks distinct\n",
    "                    out_f.write(content)\n",
    "                    if i != 13:\n",
    "                        out_f.write(\"\\n\\n\")\n",
    "\n",
    "            print(\"Merged pages into:\", final_path)\n",
    "            \n",
    "            #bam nut xoa tat ca\n",
    "            try:\n",
    "                clear_btn = WebDriverWait(driver, 30).until(EC.element_to_be_clickable((By.ID, \"component-13\")))\n",
    "                clear_btn.click()\n",
    "                print(\"Clicked Clear button (component-13)\")\n",
    "                # wait for the upload input to become available again before processing next file\n",
    "                WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"input[type='file'][data-testid='file-upload']\")))\n",
    "                time.sleep(1)\n",
    "            except Exception as e:\n",
    "                print(\"Failed to click Clear button or wait for reset:\", e)\n",
    "\n",
    "            #doi no clear xong nghia la cai cho de drop file xuat hien lai\n",
    "            try:\n",
    "                drop_selector = \"div.wrap.svelte-12ioyct\"\n",
    "                WebDriverWait(driver, 1800).until(EC.visibility_of_element_located((By.CSS_SELECTOR, drop_selector)))\n",
    "                print(\"Drop-area div appeared\")\n",
    "            except Exception as e:\n",
    "                print(\"Timeout waiting for drop-area div to appear:\", e)\n",
    "            print()\n",
    "    print(pdf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8977c9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "log_dir = Path(data_dir)\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "log_path = log_dir / \"process.log\"\n",
    "\n",
    "logger = logging.getLogger(\"pdf_processor\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# avoid adding duplicate handlers when re-running the cell\n",
    "if not any(isinstance(h, RotatingFileHandler) and h.baseFilename == str(log_path) for h in logger.handlers):\n",
    "    fh = RotatingFileHandler(str(log_path), maxBytes=5 * 1024 * 1024, backupCount=5, encoding=\"utf-8\")\n",
    "    fh.setLevel(logging.INFO)\n",
    "    fmt = logging.Formatter(\"%(asctime)s %(levelname)s: %(message)s\", \"%Y-%m-%d %H:%M:%S\")\n",
    "    fh.setFormatter(fmt)\n",
    "    logger.addHandler(fh)\n",
    "\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.INFO)\n",
    "    ch.setFormatter(fmt)\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "# convenience alias (use logger.info(...) or log(...))\n",
    "log = logger.info\n",
    "for folder in loading_folder:\n",
    "    pdf_files = []\n",
    "    folder_path = os.path.join(data_dir, folder)\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.lower().endswith('.pdf'): #Duyet tung file pdf\n",
    "            pdf_files.append(file)\n",
    "            file_path = os.path.abspath(os.path.join(folder_path, file))\n",
    "            file_no_ext = os.path.splitext(file)[0]\n",
    "            download_dir = os.path.join(folder_path, file_no_ext, \"zip\")\n",
    "\n",
    "            target_download_dir = os.path.join(os.getcwd(), download_dir)\n",
    "            os.makedirs(target_download_dir, exist_ok=True)\n",
    "            download_dir = target_download_dir\n",
    "            before_files = set(os.listdir(download_dir))\n",
    "\n",
    "            timeout = 1800\n",
    "            end_time = time.time() + timeout\n",
    "            downloaded = None\n",
    "            while time.time() < end_time:\n",
    "                time.sleep(0.5)\n",
    "                new_files = before_files\n",
    "                if new_files:\n",
    "                    for f in new_files:\n",
    "                        if not f.endswith('.crdownload'):\n",
    "                            downloaded = f\n",
    "                            break\n",
    "                if downloaded:\n",
    "                    break\n",
    "\n",
    "            if downloaded:\n",
    "                print(\"Downloaded file:\", downloaded)\n",
    "            else:\n",
    "                print(\"No completed download detected within timeout.\")\n",
    "            \n",
    "            #giai nen file\n",
    "            import os, zipfile\n",
    "            import logging\n",
    "            from logging.handlers import RotatingFileHandler\n",
    "            from pathlib import Path\n",
    "\n",
    "            zip_path = os.path.join(download_dir, downloaded)  # uses existing vars\n",
    "            extract_to = os.path.join(folder_path, file_no_ext, \"output\")\n",
    "\n",
    "            with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "                z.extractall(extract_to)\n",
    "\n",
    "            print(\"Extracted:\", zip_path, \"->\", extract_to)\n",
    "\n",
    "            #ghep lai thanh 1 file md\n",
    "            suffix = os.path.splitext(f)[0].split('_')[-1]  # e.g. 'ef13eefa' from 'layout_results_ef13eefa.zip'\n",
    "            final_path = os.path.join(extract_to, \"final.md\")\n",
    "\n",
    "            with open(final_path, \"w\", encoding=\"utf-8\") as out_f:\n",
    "                for i in range(0, 100):\n",
    "                    part_name = f\"demo_{suffix}_page_{i}.md\"\n",
    "                    part_path = os.path.join(extract_to, part_name)\n",
    "                    if not os.path.exists(part_path):\n",
    "                        #print(\"Missing:\", part_name)\n",
    "                        continue\n",
    "                    with open(part_path, \"r\", encoding=\"utf-8\") as part_f:\n",
    "                        content = part_f.read()\n",
    "                    # separate pages with two newlines to keep markdown blocks distinct\n",
    "                    out_f.write(content)\n",
    "                    if i != 13:\n",
    "                        out_f.write(\"\\n\\n\")\n",
    "\n",
    "            print(\"Merged pages into:\", final_path)\n",
    "    print(pdf_files)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8d9fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43b745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import base64\n",
    "\n",
    "print(\"Starting post-processing of existing final.md files...\")\n",
    "\n",
    "# Iterate through the main folders you processed before\n",
    "for folder_name in loading_folder:\n",
    "    folder_path = os.path.join(data_dir, folder_name)\n",
    "    \n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "\n",
    "    # Iterate through the subdirectories created for each PDF\n",
    "    for pdf_subfolder_name in os.listdir(folder_path):\n",
    "        pdf_subfolder_path = os.path.join(folder_path, pdf_subfolder_name)\n",
    "        \n",
    "        if not os.path.isdir(pdf_subfolder_path):\n",
    "            continue\n",
    "            \n",
    "        # Define the path to the final.md file\n",
    "        output_dir = os.path.join(pdf_subfolder_path, \"output\")\n",
    "        print(final_path)\n",
    "        final_path = os.path.join(output_dir, \"final.md\")\n",
    "\n",
    "        # Check if final.md exists before trying to process it\n",
    "        if os.path.exists(final_path):\n",
    "            \n",
    "            # --- Core processing logic starts here ---\n",
    "            \n",
    "            image_dir = os.path.join(output_dir, \"images\")\n",
    "            os.makedirs(image_dir, exist_ok=True)\n",
    "\n",
    "            with open(final_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "\n",
    "            image_counter = 0\n",
    "            \n",
    "            def replace_base64_with_path(match):\n",
    "                global image_counter\n",
    "                image_counter += 1\n",
    "                \n",
    "                base64_data = match.group(1)\n",
    "                \n",
    "                # Fix potential Base64 padding errors\n",
    "                missing_padding = len(base64_data) % 4\n",
    "                if missing_padding:\n",
    "                    base64_data += '=' * (4 - missing_padding)\n",
    "                    \n",
    "                try:\n",
    "                    image_data = base64.b64decode(base64_data)\n",
    "                    image_filename = f\"image_{image_counter}.png\"\n",
    "                    image_save_path = os.path.join(image_dir, image_filename)\n",
    "                    \n",
    "                    with open(image_save_path, \"wb\") as img_file:\n",
    "                        img_file.write(image_data)\n",
    "                        \n",
    "                    relative_image_path = os.path.join(\"images\", image_filename).replace('\\\\', '/')\n",
    "                    return f\"![]({relative_image_path})\"\n",
    "                except Exception as e:\n",
    "                    print(f\"  - Error decoding/saving image {image_counter} in {final_path}: {e}\")\n",
    "                    return match.group(0) # Return original match on error\n",
    "\n",
    "            # Regex to find markdown images with Base64 data\n",
    "            base64_pattern = re.compile(r\"!\\[.*?\\]\\(data:image;base64,(.*?)\\)\")\n",
    "            \n",
    "            # Perform the replacement\n",
    "            new_content = base64_pattern.sub(replace_base64_with_path, content)\n",
    "            \n",
    "            # Overwrite the final.md with the new content\n",
    "            with open(final_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(new_content)\n",
    "            \n",
    "            if image_counter > 0:\n",
    "                print(f\"Processed {final_path} and extracted {image_counter} images.\")\n",
    "            \n",
    "            # --- Core processing logic ends here ---\n",
    "\n",
    "print(\"\\nPost-processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8960c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd933f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "options.add_experimental_option(\"prefs\", {\n",
    "  \"download.default_directory\": \"D\\\\Python\\\\DataForge-automated\\\\MathTHPT2025\",\n",
    "  \"download.prompt_for_download\": False,\n",
    "  \"download.directory_upgrade\": True,\n",
    "  \"safebrowsing.enabled\": False,\n",
    "  \"safebrowsing.ebabled\": \"false\"\n",
    "})\n",
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7bf120",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import os\n",
    "import re\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# IMPORTANT: Ensure the Selenium 'driver' variable is initialized and running\n",
    "# from your previous notebook cells before you run this one.\n",
    "\n",
    "print(\"Starting HTML table-to-image conversion process...\")\n",
    "\n",
    "# UPDATED REGEX: Now looks for <table>...</table> blocks, spanning multiple lines.\n",
    "table_pattern = re.compile(r'(<table.*?>.*?</table>)', re.DOTALL)\n",
    "\n",
    "# Use the same 'data_dir' and 'loading_folder' variables from your previous cells.\n",
    "for folder_name in loading_folder:\n",
    "    folder_path = os.path.join(data_dir, folder_name)\n",
    "    \n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "\n",
    "    # Iterate through the subdirectories created for each PDF\n",
    "    for pdf_subfolder_name in os.listdir(folder_path):\n",
    "        pdf_subfolder_path = os.path.join(folder_path, pdf_subfolder_name)\n",
    "        \n",
    "        if not os.path.isdir(pdf_subfolder_path):\n",
    "            continue\n",
    "            \n",
    "        output_dir = os.path.join(pdf_subfolder_path, \"output\")\n",
    "        final_md_path = os.path.join(output_dir, \"final.md\")\n",
    "\n",
    "        if os.path.exists(final_md_path):\n",
    "            with open(final_md_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "\n",
    "            image_dir = os.path.join(output_dir, \"images\")\n",
    "            os.makedirs(image_dir, exist_ok=True)\n",
    "            \n",
    "            table_counter = 0\n",
    "\n",
    "            # This function will be called for each table found by the regex\n",
    "            def replace_table_with_image(match):\n",
    "                global table_counter\n",
    "                table_counter += 1\n",
    "                \n",
    "                # This variable now contains the full <table>...</table> string\n",
    "                html_table_string = match.group(0)\n",
    "                \n",
    "                # Create a simple, self-contained HTML file to render the table\n",
    "                # We no longer need to convert from Markdown, we can use the HTML directly.\n",
    "                html_for_render = f\n",
    "                <html>\n",
    "                <head>\n",
    "                    <style>\n",
    "                        body {{ font-family: sans-serif; background-color: white; display: inline-block; padding: 10px; }}\n",
    "                        table {{ border-collapse: collapse; margin: 1px; }}\n",
    "                        th, td {{ border: 1px solid #ccc; padding: 8px; text-align: left; }}\n",
    "                        th {{ background-color: #f2f2f2; }}\n",
    "                    </style>\n",
    "                </head>\n",
    "                <body>{html_table_string}</body>\n",
    "                </html>\n",
    "                \n",
    "                \n",
    "                # Write to a temporary HTML file\n",
    "                temp_html_path = os.path.abspath(\"temp_table.html\")\n",
    "                with open(temp_html_path, \"w\", encoding=\"utf-8\") as temp_f:\n",
    "                    temp_f.write(html_for_render)\n",
    "\n",
    "                try:\n",
    "                    # Use Selenium to open the local file and screenshot the table\n",
    "                    driver.get(f\"file://{temp_html_path}\")\n",
    "                    table_element = driver.find_element(By.TAG_NAME, 'table')\n",
    "                    \n",
    "                    image_filename = f\"table_{table_counter}.png\"\n",
    "                    image_save_path = os.path.join(image_dir, image_filename)\n",
    "                    \n",
    "                    # Take a screenshot of only the table element\n",
    "                    table_element.screenshot(image_save_path)\n",
    "                    \n",
    "                    # Create the relative path for the markdown link\n",
    "                    relative_image_path = os.path.join(\"images\", image_filename).replace('\\\\', '/')\n",
    "                    print(f\"  - Converted a table to '{relative_image_path}' in {output_dir}\")\n",
    "                    \n",
    "                    # Return the Markdown image link to replace the table text\n",
    "                    return f\"![]({relative_image_path})\"\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"  - Error converting table to image: {e}\")\n",
    "                    return html_table_string # On error, return the original table text\n",
    "\n",
    "            # Use re.subn to find all tables and replace them\n",
    "            new_content, num_replacements = table_pattern.subn(replace_table_with_image, content)\n",
    "            \n",
    "            if num_replacements > 0:\n",
    "                # Overwrite the final.md file with the new content\n",
    "                with open(final_md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(new_content)\n",
    "                print(f\"Processed {final_md_path}, replaced {num_replacements} table(s).\\n\")\n",
    "\n",
    "# Clean up the temporary file after the loop is done\n",
    "if os.path.exists(\"temp_table.html\"):\n",
    "    os.remove(\"temp_table.html\")\n",
    "\n",
    "print(\"All HTML table conversions are complete!\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8235ba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
